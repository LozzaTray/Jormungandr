\section{Inference}
\label{sec:inference}

Having completed the definition of the FFBM, we wish to leverage it 
to perform inference. Specifically, given a labelled network $(A, X)$, we wish to infer if and how the observed features $X$ impact the graphical structure $A$. Formally,
this means characterising the posterior distribution:
$
p(\theta|A, X) \propto p(\theta) \cdot p(A | X, \theta).
$
Although the prior is easily computable, 
computing the likelihood 
requires summing over all latent block-states, 
$p(A| X, \theta) = \sum_{b \in [B]^N} p(A | b) P(b | X, \theta)$, which is 
clearly impractical. In fact, this
approach is doubly intractable as we would also 
need to compute the normalising constant $p(A|X)$.
Therefore, following standard Bayesian practice,
instead we aim to draw samples from the posterior,
%
\begin{equation}
	\label{eqn:theta-target}
	\theta^{(t)} \sim p(\theta | A, X).
\end{equation}
%
We propose an iterative Markov chain Monte Carlo
(MCMC) approach to obtain these samples
$\{\theta^{(t)}\}$. We first draw a sample $b^{(t)}$ 
from the block membership posterior,
and then use $b^{(t)}$ to obtain a corresponding
sample $\theta^{(t)}$:
%
\begin{equation}
	b^{(t)} \stackrel{\rm distr}{\approx} p \big( b | A, X \big) 
	\quad \textrm{then} \quad
	\theta^{(t)} \stackrel{\rm distr}{\approx} 
	p\big(\theta | X, b^{(t)} \big),
\end{equation}
%
where these approximations become exact as
the number of MCMC iterations $t\to\infty$.
As described in the following subsections,
this can be implemented through a two-level
Markov chain via the Metropolis-Hastings (MH) 
algorithm \cite{hastings-alg}.
The splitting of the Markov chain into two levels allows us to side-step the summation over
all latent $b \in [B]^N$ required to directly compute the likelihood, $p(A| X, \theta)$.
The resulting $\theta^{(t)}$ samples are asymptotically
unbiased in that the expectation of 
their distribution converges to the true posterior:
%
\begin{equation}
\lim_{t\to\infty}
\Expect_{b^{(t)}} \left[p \left( \theta | X, b^{(t)} \right) \right] = \sum_{b \in [B]^N} p(\theta | X, b) p(b | A, X) = p(\theta | A, X).
\label{eqn:theta-unbiased}
\end{equation}
%
This is an example of a pseudo-marginal approach;
see, e.g., Andrieu and Roberts~\cite{pseudo-marginal} 
for a detailed rigorous derivation based on~(\ref{eqn:theta-unbiased}).
%
\begin{figure}[!ht]
	\centering

	\begin{tikzpicture}[
		scale=0.8, every node/.style={transform shape},
		roundnode/.style={circle, draw=black, minimum size=12mm},
		squarednode/.style={rectangle, draw=black, minimum size=12mm}
		]
		% nodes
		\node[roundnode] (b0) at (0, 2) {$b^{(t)}$};
		\node[roundnode] (b1) at (5, 2) {$b'$};
		\node[roundnode] (b2) at (10, 2) {$b^{(t+1)}$};
		\node[roundnode] (t0) at (0, 0) {$\theta^{(t)}$};
		\node[roundnode] (t1) at (5, 0) {$\theta'$};
		\node[roundnode] (t2) at (10, 0) {$\theta^{(t+1)}$};
		
		% arrows
		\draw[->] (b0) to node[above] {$\sim q_b ( b^{(t)}, b' | A )$} (b1);
		\draw[->] (b1) to node[above] {$\alpha_b (b, b' | A )$} (b2);
		\draw[->] (b0) [out=25, in=155] to node[above] {$1-\alpha_b$} (b2);
		
		\draw[->] (t0) to node[above] {$\sim q_\theta(\theta^{(t)}, \theta' | X, b^{(t)})$} (t1);
		\draw[->] (t1) to node[above] {$\alpha_\theta (\theta, \theta' | X, b^{(t)})$} (t2);
		\draw[->] (t0) [out=-25, in=-155] to node[below] {$1-\alpha_\theta$} (t2);
		
		\draw[dashed, ->] (b0) to (2, 0.8);
		\draw[dashed, ->] (b0) to (6.5, 0.8);
		
	\end{tikzpicture}
	\caption{$\theta$-sample generation.}
	\label{fig:samp-sequence}
\end{figure}
 
Figure \ref{fig:samp-sequence} shows an overview of the proposed method, with $q$ and $\alpha$ denoting the MH proposal distribution and acceptance probability respectively.
Note the importance of the simplification in~(\ref{eqn:b-pseudo-prior}). 
As evaluating $p(b| X)$ does not depend on $X$, 
we do not need $X$ to sample $b$.
And on the other level, in order to obtain 
samples for $\theta$
we use only $b$ but not $A$, as $(\theta \indep A )| b$. 

\FloatBarrier
\subsection{Sampling block memberships}

To generate the required $b$-samples, we adopt the MCMC
procedure of
\cite{Peixoto-MCMC},
which relies on writing the posterior in the following form,
%
\begin{equation}
	p(b | A, X) \propto p(A | b, X) \cdot p(b | X) = \pi_b(b),
\end{equation}
%
where $\pi_b(\cdot)$ denotes the un-normalised target density.
Since we are using the microcanonical SBM formulation, there is only one 
value of $\psi$ that is compatible with the given $(A, b)$ pair;
recall the constraints in~(\ref{eqn:sbm-constraints}).
We denote this value $\psi^* = \{\psi_k^*, \psi_e^*\}$. Therefore, 
the summation over all $\psi$ needed to evaluate $p(A | b, X)$ reduces to just the single $\psi^*$ term:
$p(A | b, X) = \sum_{\psi} \nolimits p(A , \psi | b, X) = p(A, \psi^* | b, X)$.
In
this context, the microcanonical entropy of the configuration $b$
is,
%
\begin{equation}
	S(b) \coloneqq - \log \pi_b(b) = - \Big( \log p(A | b, \psi^*) + \log p(\psi^*, b | X) \Big),
	\label{eqn:dl-form}
\end{equation}
%
which can be thought of as the optimal
``description length'' of the graph. 
This expression will later be employed 
to help evaluate experimental results. 
The exact form of the proposal $q_b$ is explored thoroughly in
\cite{Peixoto-MCMC} and not repeated here. We use the \verb*|graph-tool| \cite{peixoto_graph-tool_2014}
library for Python, which implements this algorithm.
The only modification is in 
the prior $p(b)$ that we replace with $p(b|X)=B^{-N}$, 
which cancels out in the MH accept-reject step as it is independent of $b$.

\subsection{Sampling feature-to-block generator parameters}
\label{s:sfb}

The target distribution for the required $\theta$-samples 
is the posterior of $\theta$ given the values of the pair $(X, b)$. 
We write this as,
%
\begin{equation}
	\pi_\theta(\theta) \propto p(\theta | X, b) \propto p(b | X, \theta) p(\theta) \propto  \exp \left( - U(\theta) \right),
	\label{eq:U}
\end{equation}
%
where $U(\theta)$ denotes the negative log-posterior. Let $y_{ij} \coloneqq \one \left\{ b_i = j \right\}$ and $a_{ij} \coloneqq \phi_j(x_i; \theta)$. 
Discarding constant terms, $U(\theta)$ can be expressed as,
%
\begin{equation}
	U(\theta) = \left( \sum_{i \in [N]} \sum_{j \in [B]} y_{ij} \log \frac{1}{a_{ij}} \right)
	+ \frac{1}{2\sigma_\theta^2} \|\theta\|^2 = N \cdot \Lcal(\theta) + \frac{1}{2\sigma_\theta^2} \|\theta\|^2;
	\label{eqn:U-form}
\end{equation}
%
see Appendix \ref{appdx:form-U}. The function $U(\theta)$ is a typical objective function for neural network training. The first term $N \cdot \Lcal(\theta)$ is introduced by the likelihood and represents the cross-entropy between the graph-predicted and feature-predicted block memberships. 
The second term, introduced by the prior, brings a form of regularisation, guarding against over-fitting. In order to draw samples from the posterior 
$\pi_\theta \propto \exp(-U)$ we adopt the Metropolis-adjusted Langevin 
algorithm (MALA) \cite{mala-tweedie}, which uses $\nabla U$ to bias the 
proposal towards regions of higher density. Given the current 
sample $\theta$, a proposed 
new sample $\theta'$ is generated from,
%
\begin{equation*}
	\theta' \sim q_\theta\big(\theta, \theta'\big) 
	= \Gaussian \big( \theta' ; \theta - h \nabla U(\theta), 2h I \big),
\end{equation*}
%
where $\xi \sim \Gaussian(0, I)$ and $h$ is a step-size parameter 
which may vary with the sample index.
Without the injected noise term $\xi$, MALA is equivalent to gradient descent. We require $\xi$ to fully explore the parameter space. 
The term $\nabla U$ has an easy to compute analytic form (derived in Appendix \ref{appdx:form-U}).

\subsection{Sampling sequence}
\label{s:ss}

So far, each $\theta^{(t)}$ update has used its corresponding $b^{(t)}$ sample. This means the evaluation of $U^{(t)}$ and $\nabla U^{(t)}$ has high variance, leading to longer burn-in and possibly slower MCMC convergence. The only link between $b^{(t)}$ and $\theta^{(t)}$ is in the evaluation of $U^{(t)}$ and $\nabla U^{(t)}$ which depends only on the matrix $y^{(t)}$ with entries $y_{ij}^{(t)} \coloneqq \one\{b_i^{(t)} = j\}$. We would rather deal with the expectation of each $y_{ij}^{(t)}$:
%
\begin{equation}
	\Expect \left[ y_{ij}^{(t)} \right] = \Expect_{b^{(t)}} \left[ \one \left( b_{i}^{(t)} = j \right) \right]
	= p(b_i = j | A, X).
\end{equation}
%
An unbiased estimate for this can be obtained using 
the thinned $b$-samples after burn-in.
Let $\Tcal_b$  denote the retained set of indices 
for the $b$-samples and $\Tcal_\theta$ similarly for the $\theta$-chain. 
The unbiased estimate for $y_{ij}^{(t)}$ is then:
%
\begin{equation}
	\hat{y}_{ij} \coloneqq \frac{1}{|\Tcal_b|} \sum_{t \in \Tcal_b} y_{ij}^{(t)} = \frac{1}{|\Tcal_b|} \sum_{t \in \Tcal_b} \one\{b_i^{(t)} = j\}.
	\label{eqn:y-hat}
\end{equation}
%
The same matrix $\hat{y}$ is used in each $\theta^{(t)}$ update step.
This way, it is not necessary to run the $b$ and $\theta$ Markov chains 
concurrently. Instead, we run the $b$-chain to completion and use it 
to generate $\hat{y}$ also allowing us to vary the lengths of each.

\subsection{Dimensionality reduction}
\label{sec:dim-reduction}

The complexity of evaluating $U$ and $\nabla U$ is linear in 
the dimension of the feature space $D$,
so there is computational incentive to reduce $D$.
Given the samples $\left\{ \theta^{(t)} \right\}$, we can compute the empirical mean and standard deviation of each component of $\theta$. 
Switching to the matrix notation $W$ for $\theta$,
let:
%
\begin{equation}
	\hat{\mu}_{ij} \coloneqq \frac{1}{|\Tcal_\theta|} \sum_{t \in \Tcal_\theta} W_{ij}^{(t)} \qquad \textrm{and} \qquad
	\hat{\sigma}_{ij}^2 \coloneqq \frac{1}{|\Tcal_\theta|} \sum_{t \in \Tcal_\theta} \left( W_{ij}^{(t)} - \hat{\mu}_{ij} \right)^2.
\end{equation}
%
A simple heuristic to discard the least important features requires specifying a cutoff $c > 0$ and a multiplier $k > 0$. We define the function $\Fcal_i(j)$ 
as in~(\ref{eqn:fij}) and only keep features with indices $d \in \Dcal'$, where $\Dcal'$ is given in~(\ref{eqn:kept-feature-set}).
%
\begin{align}
	\Fcal_i(j) &\coloneqq (\hat{\mu}_{ij} - k \hat{\sigma}_{ij}, \hat{\mu}_{ij} + k \hat{\sigma}_{ij}) \cap (-c, +c),
	\label{eqn:fij} \\
	\Dcal' &\coloneqq \left\{ j \in [D] : \exists i \in [B] \textrm{ s.t. }  \Fcal_i(j) = \emptyset \right\}.
	\label{eqn:kept-feature-set}
\end{align}
%
Intuitively, this means discarding any feature $j$ for which 
$(\hat{\mu}_{ij} - k\hat{\sigma}_{ij}, \hat{\mu}_{ij} + k \hat{\sigma}_{ij})$ overlaps with
$(-c, c)$ for all $i$. If we were to use the Laplace approximation for the posterior $p(W_{ij} | A, X) \approx \Gaussian(W_{ij}; \hat{\mu}_{ij}, \hat{\sigma}_{ij}^2)$, then this would be analogous to a hypothesis test on the magnitude of $W_{ij}$ compared to $c$ with multiplier $k$ in~(\ref{eqn:fij}) determining the degree of significance of the result. Conversely, if we want to fix the number of dimensions in our reduced feature set $|\Dcal'|=D'$, the problem then becomes finding the largest value of $c$ such that $|\Dcal'|=D'$ given $k=k_0$:
%
\begin{equation}
	c^* = \argmax \{c>0\; : \;|\Dcal'| = D', k=k_0\}.
	\label{eqn:c-star}
\end{equation}

