\section{Experimental results}
\label{sec:experiments}

We apply our proposed methods to a variety of real-world datasets.
For reference, the inferred partitions for all of these are given on Figure~\ref{fig:graphs-all}.
%We employ the following metrics to assess model performance. 
%First, the average
%description length per entity (nodes and edges) 
%$\bar{S}_e$ 
%used to gauge the SBM fit is defined as:
%%
%\begin{equation}
%	\bar{S}_e \triangleq \frac{1}{(N+E) |\mathcal{T}_b|} \sum_{t\in \mathcal{T}_b} S \left( b^{(t)} \right).
%	\label{eqn:mean-dl}
%\end{equation}
%%
%Next, to assess the performance of the feature-to-block predictor, 
%the vertex set $[N]$ 
%is partitioned at random so that 
%a constant fraction $f$ of vertices form the training set $\mathcal{G}_0$ and 
%the remainder form the test set $\mathcal{G}_1$.
%The $b$-chain is run using the whole network but only vertices $v \in \mathcal{G}_0$ are 
%used for the $\theta$-chain. 
%Then the  the average cross-entropy loss 
%over each set is used to gauge the quality of the fit,
%%
%\begin{equation}
%	\bar{\mathcal{L}}_\star \triangleq \frac{1}{|\mathcal{T}_\theta|} \sum_{t \in \mathcal{T}_\theta} \mathcal{L}_\star^{(t)},
%	\quad \textrm{where} \quad
%	\mathcal{L}_\star^{(t)} \triangleq \frac{1}{|\mathcal{G}_\star|} \sum_{i \in \mathcal{G}_\star}\sum_{j \in [B]} \hat{y}_{ij} \log \frac{1}{\phi_j \left(x_i; \theta^{(t)} \right)},
%	\label{eqn:cross-entropy-loss}
%\end{equation}
%%
%where $\star \in \{0, 1\}$ toggles between the training and test sets
%and $\hat{y}_{ij}$ is defined in~(\ref{eqn:y-hat}).
%%
%Nevertheless, the cross-entropy loss is a coarse measure of fit. 
%A new measure, specific to each detected block,
%can be defined as follows. Let
%$\mathcal{B}_\star(j)$ 
%be the set of vertices with maximum a posteriori probability of belonging 
%to block~$j$,
%$
%	\mathcal{B}_\star(j) \triangleq \{i \in \mathcal{G}_\star : \hat{b}_i = j\},
%$
%where
%$ 
%	\hat{b}_i \triangleq \underset{j}{\operatorname{argmax}}\hat{y}_{ij},
%$
%and
%define the {\em block-accuracy} for block $j$ as,
%%
%\begin{equation}
%	\eta_\star(j) \triangleq \frac{1}{|\mathcal{B}_\star (j)| \cdot 
%	|\mathcal{T}_\theta| } 
%	\sum_{i \in \mathcal{B}_\star (j)}  \sum_{t \in \mathcal{T}_\theta}
%	\boldsymbol{1} \left\{\hat{b}_i = \underset{j}{\operatorname{argmax}}\phi_j \left( x_i; \theta^{(t)} \right) \right\}.
%	\label{eqn:accuracy}
%\end{equation}
%%
%This effectively tests whether the feature-to-block and 
%graph-to-block predictions agree in their largest component.
%For the higher-dimensional datasets, we also apply the 
%dimensionality reduction method 
%of Section~\ref{sec:dim-reduction}.  
%We then retrain the feature-block predictor using only the retained 
%feature set $\mathcal{D}'$, and report the log-loss over the training and 
%test sets for the reduced classifier -- 
%denoted $\bar{\mathcal{L}}_0'$ and $\bar{\mathcal{L}}_1'$ respectively. 
