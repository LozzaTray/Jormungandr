\section{Experimental results}
\label{sec:experiments}

We apply our proposed methods to a variety of real-world datasets.
The inferred partitions $b$ for all of these are given on Figure~\ref{fig:graphs-all}.
To assess model performance,
%
the average
description length per entity (nodes and edges) 
$\bar{S}_e$ 
is used to gauge the SBM fit,
and
the vertex set $[N]$ is partitioned at random into training and test sets, 
$\mathcal{G}_0$ and $\mathcal{G}_1$,
%
to assess the performance of the feature-to-block predictor.
The average cross-entropy loss 
over each set,
denoted $\bar{\mathcal{L}}_\star$,
is used to gauge the quality of the fit.

For higher-dimensional datasets, we develop a novel 
dimensionality reduction method to select only the top $D'$ features.  
We then retrain the feature-block predictor using only the retained 
feature set, and report the cross-entropy loss 
$\bar{\mathcal{L}}_\star'$
over the training and 
test sets for the reduced classifier.

Table~\ref{tab:results} summarises the results for each experiment. 
We see that the dimensionality reduction procedure 
brings the training and test losses closer, indicating that
the retained features
are indeed well correlated with the underlying graphical 
partition and that the approach generalises correctly. 
